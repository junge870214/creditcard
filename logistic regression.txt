概述
scikit-learn中，与逻辑回归有关的主要是这三个类：LogisticRegression,LogisticRegressionCV和logistic_regression_path。
其中LogisticRegression和LogisticRegressionCV的主要区别是CV使用了交叉验证来选择正则化系数C，其他使用区别不大。
正则化选择参数：penalty
penalty可选值为"l1","l2"，默认l2。
只为了解决过拟合，直接选l2就够了，如果选了l2后还是过拟合，可以考虑l1，模型特征较多，希望让模型系数稀疏化，可以考虑l1
penalty的选取会影响损失函数优化算法的选取，即：solver参数。
如果选l2正则化，四种优化算法：newton-cg，lbfgs，liblinear，sag都可选。
选l1正则化，只能选liblinear，因为其与三种优化算法都需要损失函数的一阶二阶连续可导。
solver参数：
liblinear：使用开源liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数
lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数
newton-cg：牛顿法家族的一种，利用损失函数二阶导数即海森矩阵来优化迭代损失函数
sag：随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适用于样本数据较多的情况
分类参数：muiti_class
multi_class参数决定了我们分类方式的选取，默认为ovr
在二元问题上没有区别，区别在多元逻辑回归上。
类型权重参数：class_weight
class_weight表示分类模型各种类型的权重，主要解决：误分类代价很高，样本高度失衡
calss_weight可选balanced，让库自己计算权重，样本量越多，权重越低。
样本权重参数：sample_weight
